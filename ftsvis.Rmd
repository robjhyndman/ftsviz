---
title: "Data visualization for functional time series"
author: "Rob J Hyndman"
date: "11 December 2018"
abstract: Any good data analysis begins with a careful graphical exploration of the observed data. For functional time series data, this area of statistical analysis has been largely neglected. I will look at the tools that are available such as rainbow plots and functional box plots, and propose several new tools including functional ACF plots, functional season plots, calendar plots, and embedded pairwise distance plots. These will be illustrated using pedestrian count data in Melbourne, smart meter data from Ireland, and mortality data from France.
output:
  binb::monash:
    fig_height: 5
    fig_width: 8
    highlight: tango
    incremental: no
    colortheme: monashblue
    keep_tex: yes
    toc: yes
    includes:
      in_header: rjh.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, cache=TRUE,
  dev.args=list(bg=grey(0.9), pointsize=11))
library(tidyverse)
library(lubridate)
library(glue)
library(tsibble)
library(sugrrants)
source("data/functions.R")
```

# Using ggplot2 for functional time series

# Time-indexed probability distributions

## Smart meter data

\alert{vec.ausnetservices.com.au}

\vspace*{.3cm}

\centerline{\includegraphics[width=15cm,height=15cm]{ausnet.png}}

```{r holidays}
vic_holidays <- holiday_aus(2017:2018, state = "VIC")
```

```{r pctiles}
pcgrid <- seq(10,90,by=1)/100
pccols <- rainbow(120)[1:100]
#c("#1b9e77","#d95f02","#7570b3","#d95f02","#1b9e77")
```

## George's data

```{r georgedata, dependson='holidays'}
george <- read_csv("data/smart_meter/george1.csv", skip=1,
  col_names = c("id", "date", paste0("d", 1:48), paste0("stuff", 1:5)),
  col_types = "ccddddddddddddddddddddddddddddddddddddddddddddddddccccc")
george <- george %>% filter(id == 300)
george <- george %>%
  mutate(date = ymd(date)) %>%
  select(id:d48) %>%
  gather(halfhour, kwh, d1:d48) %>%
  mutate(halfhour = as.numeric(sub("d", "", halfhour))/2) %>%
  arrange(date, halfhour) %>%
  mutate(wday = lubridate::wday(date, label = TRUE, abbr = TRUE, week_start = 1),
         month = lubridate::month(date, label = TRUE, abbr = TRUE),
         year = lubridate::year(date),
         tow = as.numeric(wday)*24 - 24 + halfhour,
         dt = ymd_hm(glue("{date} 0:00"), tz = "Australia/Melbourne") +
           minutes(60*halfhour),
         work = ifelse(wday %in% c("Mon", "Tue", "Wed", "Thu", "Fri"), 1, 0),
         work = ifelse(date %in% vic_holidays$date, 0, work))
```

```{r plotdata, dependson='georgedata'}
george %>%
  ggplot(aes(x=dt, y=kwh)) +
    geom_line() +
    scale_x_datetime(date_breaks="1 month",
                     date_minor_breaks="1 week",
                     date_labels="%b %y") +
    theme(axis.text = element_text(hjust = 0)) +
    xlab("Month") + ylab("kWh")
```

## George's data

```{r calendar, dependson='georgedata'}
p1 <- george %>%
  frame_calendar(x = halfhour, y = kwh, date = date, ncol = 5,margin=.1) %>%
  ggplot(aes(x = .halfhour, y = .kwh, group = date, colour=factor(work))) +
    geom_line() +
    scale_colour_brewer("work", palette = "Dark2") +
    theme(legend.position="none")
prettify(p1, nudge_x=-.5)
```

## George's data

```{r time0, dependson='georgedata',fig.height=4.08}
george %>%
  ggplot(aes(x=halfhour, y=kwh)) +
  geom_jitter(height=0, width=0.2, size=.1, alpha=0.5) + xlab("Time of day") + ylab("kWh") +
  scale_x_continuous(breaks=seq(3,24,by=3), minor_breaks = seq(0,24,by=1))
```

\vspace*{10cm}

## George's data

```{r time1, dependson='georgedata', fig.height=4.08}
george %>%
  ggplot(aes(x=halfhour, y=kwh, group=wday)) +
  geom_point(size=.1, alpha=0.25) + facet_grid(~ wday) +
  xlab("Time of day") + ylab("kWh") +
  scale_x_continuous(breaks=c(6,12,18,24),minor_breaks = seq(0,24,by=2))
```

\vspace*{10cm}

## George's data

```{r gpc, dependson=c('georgedata','pctiles')}
gpc <- george %>%
  crossing(pctile = pcgrid) %>%
  group_by(tow, pctile) %>%
  summarise(pc = quantile(kwh, unique(pctile))) %>%
  left_join(george) %>%
  select(-id, -date, -kwh, -dt,-year, -month, -work) %>%
  unique() %>%
  mutate(pcstring = factor(pctile,
                        labels=paste(round(pcgrid*100),"%",sep="")))
```

```{r time2, dependson=c('gpc','pctiles')}
gpc %>%
  filter(pcstring %in% c("10%","25%","50%","75%","90%")) %>%
  ggplot(aes(x=halfhour, group=wday)) +
    geom_point(data=george, aes(x=halfhour, y=kwh), size=.1, alpha=0.25) +
    geom_line(aes(x=halfhour, y=pc, group=pctile, col=pctile)) +
    facet_grid(~ wday) +
    xlab("Time of day") + ylab("kWh") +
    scale_x_continuous(breaks=c(6,12,18,24),minor_breaks = seq(0,24,by=2)) +
    scale_colour_gradientn(colours=pccols, name="Percentile") +
    theme(legend.position="bottom", legend.direction="horizontal",
          legend.key.width=unit(1,"cm"),
          legend.key.height=unit(.3,"cm"))
```

\vspace*{10cm}

## George's data

```{r time3, dependson=c('gpc','pctiles')}
gpc %>%
  ggplot() +
    geom_point(data=george, aes(x=halfhour, y=kwh), size=.1, alpha=0.3) +
    geom_line(aes(x=halfhour, y=pc, group=pctile, col=pctile)) +
    facet_grid(~ wday) +
    xlab("Time of day") + ylab("kWh") +
    scale_x_continuous(breaks=c(6,12,18,24),minor_breaks = seq(0,24,by=2)) +
    scale_colour_gradientn(colours=pccols,name="Percentile") +
    theme(legend.position="bottom", legend.direction="horizontal",
          legend.key.width=unit(1,"cm"),
          legend.key.height=unit(.3,"cm"))
```

\vspace*{10cm}


## Clare's data

```{r claredata, dependson='holidays'}
clare <- read_csv("data/smart_meter/clare1.csv", skip=1,
     col_names = c("id", "date", paste0("d", 1:48), paste0("stuff", 1:5)),
     col_types = "ccddddddddddddddddddddddddddddddddddddddddddddddddccccc") %>%
  filter(id == 300) %>%
  mutate(date = ymd(date)) %>%
  select(id:d48) %>%
  gather(halfhour, kwh, d1:d48) %>%
  mutate(halfhour = as.numeric(sub("d", "", halfhour))/2) %>%
  arrange(date, halfhour) %>%
  mutate(wday = lubridate::wday(date, label = TRUE, abbr = TRUE, week_start = 1),
         month = lubridate::month(date, label = TRUE, abbr = TRUE),
         year = lubridate::year(date),
         tow = as.numeric(wday)*24 - 24 + halfhour,
         dt = ymd_hm(glue("{date} 0:00"), tz = "Australia/Melbourne") +
           minutes(60*halfhour),
         work = ifelse(wday %in% c("Mon", "Tue", "Wed", "Thu", "Fri"), 1, 0),
         work = ifelse(date %in% vic_holidays$date, 0, work))
```

```{r clare2, dependson='claredata'}
clare %>%
  ggplot(aes(x=dt, y=kwh)) +
    geom_line() +
    scale_x_datetime(date_breaks="1 month",
                     date_minor_breaks="1 week",
                     date_labels="%b %y") +
    theme(axis.text = element_text(hjust = 0, size=6.5)) +
    xlab("Month") + ylab("kWh")
```

\vspace*{10cm}

## Clare's data

```{r clare3, dependson='claredata'}
p1 <- clare %>%
  frame_calendar(x = halfhour, y = kwh, date = date, ncol = 5,margin=.1) %>%
  ggplot(aes(x = .halfhour, y = .kwh, group = date, colour=factor(work))) +
    geom_line() +
    scale_colour_brewer("work", palette = "Dark2") +
    theme(legend.position="none")
prettify(p1, nudge_x=-.5)
```

\vspace*{10cm}

## Clare's data

```{r clare4, dependson='claredata', fig.height=4.35}
clare %>%
  ggplot(aes(x=halfhour, y=kwh, group=wday)) +
  geom_point(size=.1, alpha=0.25) + facet_grid(~ wday) +
  xlab("Time of day") + ylab("kWh") +
  scale_x_continuous(breaks=c(6,12,18,24),minor_breaks = seq(0,24,by=2))
```

\vspace*{10cm}

## Clare's data

```{r cpc, dependson=c('claredata','pctiles'), fig.height=4.08}
cpc <- clare %>%
  crossing(pctile = pcgrid) %>%
  group_by(tow, pctile) %>%
  summarise(pc = quantile(kwh, unique(pctile))) %>%
  left_join(clare) %>%
  select(-id, -date, -kwh, -dt,-year, -month, -work) %>%
  unique() %>%
  mutate(pcstring= factor(pctile,
                        labels=paste(round(pcgrid*100),"%",sep="")))
```

```{r clare5, dependson=c('gpc','pctiles')}
cpc %>%
  ggplot() +
    geom_point(data=clare, aes(x=halfhour, y=kwh), size=.1, alpha=0.25) +
    geom_line(aes(x=halfhour, y=pc, group=pctile, col=pctile)) +
    facet_grid(~ wday) +
    xlab("Time of day") + ylab("kWh") +
    scale_x_continuous(breaks=c(6,12,18,24),minor_breaks = seq(0,24,by=2)) +
    scale_colour_gradientn(colours=pccols,name="Percentile") +
    theme(legend.position="bottom", legend.direction="horizontal",
          legend.key.width=unit(1,"cm"),
          legend.key.height=unit(.3,"cm"))
```


\vspace*{10cm}

## Percentiles conditional on time of week
\fontsize{12}{13}\sf
\centerline{\includegraphics[width=9.8cm]{quantileplot}}

* Percentiles for each household and each half-hour of the week.
* Provides a unique fingerprint of typical usage for a given household.
* 336 probability distributions per household.
* Avoids missing data issues and variation in series length
* Avoids timing of household events, holidays, etc.
* Allows clustering of households based on probabilistic behaviour rather than coincident behaviour.
* A more complicated version also allows it to change across the year.

## Finding anomalous smart meters

```{r load, include=FALSE}
load("data/DT.rda")
load("data/qdemand.rda")
load("data/jsdmat.rda")
source("data/functions.R")
```

\begin{block}{Irish smart meter data}
\begin{itemize}\tightlist
 \item 500 households from smart metering trial:\\ 14 July 2009 -- 31 December 2010.
 \item Electricity consumption at 30-minute intervals.
 \item Heating/cooling energy usage excluded.
\end{itemize}
\end{block}

\placefig{1.}{5.5}{width=4.5cm, height=1.8cm, keepaspectratio=false}{timeplot}
\placefig{7.1}{5.5}{width=4.5cm, height=1.8cm, keepaspectratio=false}{quantileplot}
\begin{textblock}{3}(5.75,6.2)\Large
$\longrightarrow$
\end{textblock}
\vspace*{2.7cm}\fontsize{13}{15}\sf

The time series of $535\times48$ observations per household is mapped to a set of $7\times48\times99$ percentiles giving a bivariate surface for each household.

## Finding anomalous smart meters
\fontsize{14}{15}\sf\vspace*{-0.2cm}
\begin{block}{}
Can we compute pairwise distances between all households?
\end{block}

\placefig{1}{2.9}{width=4.2cm, height=1.8cm, keepaspectratio=false}{quantileplot}
\placefig{7.4}{2.9}{width=4.2cm, height=1.8cm, keepaspectratio=false}{quantile2plot}
\begin{textblock}{2.2}(5.2,3.2)
\centerline{$\leftarrow ~ ? ~ \rightarrow$}
\fontsize{11}{12}\sf
\centerline{Distance}
\end{textblock}

\vspace*{2.1cm}\pause

 * Jensen-Shannon measure gives distance between two densities\pause
 * Distance between household $i$ and household $j$:\newline  $\Delta_{ij} =$ sum of $7\times48$ JS distances.\pause
 * Similarity between two households: $\displaystyle w_{ij} = \exp(-\Delta_{ij}^2/h^2)$\pause
 * Household typicality: $\displaystyle f_i = \sum_{j} w_{ij}$.



## Most typical household

```{r typical, dependson='load'}
elecembed <- embedding(jsdmat, m=2)
# Look at modal observations
fxyhi <- kdedist(elecembed$distances, bandwidth=1e5)
mode1 <- order(fxyhi,decreasing=TRUE)[1]
mode2 <- order(fxyhi,decreasing=TRUE)[2]
mode3 <- order(fxyhi,decreasing=TRUE)[3]
qdemandplot(mode1)
```

## Most anomalous household

```{r outlier1, dependson='typical'}
outlier1 <- order(fxyhi,decreasing=FALSE)[1]
qdemandplot(outlier1)
```

## Laplacian eigenmaps
\fontsize{13}{15}\sf

> - **Idea:** Embed conditional densities in a 2d space where the distances are preserved "as far as possible".
> -
 \begin{align*}
 \\[-1.36cm]
 \text{Let}\quad
   \bm{W} &=[w_{ij}] &&\text{~~ where~}w_{ij} = \exp(-\Delta_{ij}^2/h^2).\\
   \bm{D} &= \text{diag}(\hat{f}_i) &&\text{~~ where~}\hat{f}_i = \sum_{j=1}^n w_{ij}\\
   \bm{L} &=\bm{D}-\bm{W} &&\text{~~ (the Laplacian matrix).}\hspace{5cm}
 \end{align*}
> - Solve generalized eigenvector problem: $\bm{L}\bm{e} = \lambda \bm{D}\bm{e}$.
> - Let $\bm{e}_k$ be eigenvector corresponding to $k$th \emph{smallest} eigenvalue.
> - Then $\bm{e}_2$ and $\bm{e}_3$ create an embedding of households in 2d space.

## Key property of Laplacian embedding

Let $y_i = (e_{2,i},e_{3,i})$ be the embedded point corresponding to household $i$.

\begin{block}{}
Then the Laplacian eigenmap minimizes
$$
  \sum_{ij} w_{ij}(y_i-y_j)^2 = \bm{y}'\bm{L}\bm{y} \qquad\text{such that}\quad
\bm{y}'\bm{D}\bm{y}=1.
$$
\end{block}\pause

 > - the most similar points are as close as possible.
 > - First eigenvalue is 0 due to translation invariance.
 > - Equivalent to optimal embedding using Laplace-Beltrami operator on manifolds.

## Visualization via embedding

\begin{textblock}{5}(0.2,1.3)
\fontsize{12}{13}\sf
\begin{block}{}
Embed conditional densities in a 2d space where the distances are preserved ``as far as possible''.
\end{block}

\fontsize{11}{11}\sf
\begin{itemize}\tightlist
\item With more data, we might be able to find clusters of similar households.
\item Anomalous households may be due to:
\begin{itemize}\fontsize{11}{11}\sf
\item malfunctioning equipment
\item unusual schedules or behaviours
\item nefarious activity
\end{itemize}
\end{itemize}
\end{textblock}

```{r elecembed, fig.height=5, fig.width=6, out.width="6.4cm", fig.align='right', dependson='typical'}
plot(elecembed, embedded=FALSE, noutliers=1) +
  xlim(-2.7,1.9) +
  ggtitle("Laplacian eigenmap of 500 Irish households")
```

\only<2>{\begin{textblock}{3.5}(9,7.8)
\begin{alertblock}{}\small
Further information: \textbf{robjhyndman.com}
\end{alertblock}
\end{textblock}}
